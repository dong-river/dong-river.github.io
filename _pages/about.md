---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I am a second-year Ph.D. student at University of Cambridge working on Natural Language Processing and Large Language Models (LLM). I am supervised by Professor [Nigel Collier](https://sites.google.com/site/nhcollier/home) and advised by [Dr. Ivan Vulic](https://sites.google.com/site/ivanvulic/). My current ressearch focus is building Personalized LLM Assistant, through personalized alignment, interactive learning, and Agents.

Previously, I received my undergraduate and master's degree from University of Pennsylvania, where I was advised by Professor [Chris Callison-Burch](https://www.cis.upenn.edu/~ccb/). I have also interned at Amazon, Roblox, and Sequoia Capital. 


### Publications

[Can LLM be a Personalized Judge?](https://arxiv.org/pdf/2406.11657) \\
**Yijiang River Dong**, Tiancheng Hu, Nigel Collier \\
In Findings of Empirical Methods in Natural Language Processing (EMNLP 2024)

[UNDIAL: Self-Distillation with Adjusted Logits for Robust Unlearning in Large Language Models](https://arxiv.org/abs/2402.10052)
**Yijiang River Dong**, Hongzhou Lin, Mikhail Belkin, Ramon Huerta, Ivan VuliÄ‡ \\
Under Review

[CORRPUS: Codex-Leveraged Structured Representations for Neurosymbolic Story Understanding](https://arxiv.org/abs/2212.10754) \\
**Yijiang River Dong**, Lara J Martin, Chris Callison-Burch \\
In Findings of the Association for Computational Linguistics (ACL 2023)

 <!-- senior at University of Pennsylvania studying Mathematics and Data Science. My primary research interest is incorporating knowledge and reasoning into natural language generation(NLG).  -->
<!-- I am excited about enhancing NLG's factuality, logical coherence and explainability by adding in knowledge base and world model. -->

<!-- <!-- I worked on creating new evaluation framework for NLG with Professor [Lyle Ungar](https://www.seas.upenn.edu/~ungar/)   and [Joao Sedoc](https://www.stern.nyu.edu/faculty/bio/joao-sedoc). -->